%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


\usepackage{graphicx}
\usepackage{xcolor}

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath

\renewcommand\refname{Referências}

\usepackage{algorithm}
\usepackage{algpseudocode}
% *** SPECIALIZED LIST PACKAGES ***
%
% \usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Detecção de Anomalias em Robôs Industriais}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{1\textsuperscript{st} Andre Freitas}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{}\\
Recife, Brazil \\
afs15@cin.ufpe.br}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Bianca Paes}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
bpas@cin.ufpe.br}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Caio Nascimento}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
cns@cin.ufpe.br}
\and
\IEEEauthorblockN{4\textsuperscript{rd} Rodrigo Gomes}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
rgar@cin.ufpe.br}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
A detecção automática de anomalias em robôs industriais é essencial para segurança operacional e integridade do equipamento. Este trabalho aborda a identificação de falhas mecânicas em um braço robótico UR3e utilizando dados de sensores inerciais (IMU) coletados a 10 Hz. O dataset compreende 874.937 amostras normais e 49.185 anômalas em quatro tipos de falha: colisões contra plataforma, colisões contra o braço, sobrecarga e vibração estrutural. A metodologia envolve análise exploratória, pré-processamento com filtragem Savitzky-Golay e normalização RobustScaler, e extração de sete características estatísticas por janela deslizante. A redução de dimensionalidade via remoção de correlações altas e PCA reduziu o espaço de 72 para 15 dimensões mantendo 95,28\% da variância. Foram implementados três modelos: Gaussian Mixture Model, Isolation Forest e Autoencoder Convolucional 1D. Os resultados demonstram que o GMM alcança discriminação perfeita entre classes (ROC AUC 1.0), enquanto o Autoencoder oferece flexibilidade para capturar padrões não-lineares. A abordagem fornece toolkit adaptável para monitoramento de condição em ambientes industriais.


\end{abstract}

% no keywords

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introdução}

A motivação para este estudo decorre da crescente adoção de robôs industriais em operações críticas, onde a execução de tarefas repetitivas em proximidade com operadores exige monitoramento constante. Neste contexto, a identificação automática de anomalias é essencial para detectar falhas mecânicas e interferências externas, garantindo a integridade do equipamento e a segurança do processo.

A análise baseia-se em dados de sensores inerciais (IMU), capazes de capturar a dinâmica do manipulador. O acelerômetro monitora vibrações e impactos abruptos (indicativos de colisões), enquanto o giroscópio registra a velocidade angular, permitindo identificar oscilações ou atrasos causados por cargas excessivas. O magnetômetro, mede a orientação do sistema em relação ao campo magnético terrestre, apresentando variações mais lentas e sendo sensível a interferências magnéticas inesperadas. Como o robô opera em ciclos sequenciais, os sinais normais apresentam periodicidade bem definida; desvios nesse padrão, como alterações de forma de onda ou picos de energia, constituem as assinaturas principais de condições anômalas.

O conjunto de dados utilizado provém de experimentos públicos (IEEE PerCom 2023) realizados com um braço robótico UR3e em ambiente controlado. As amostras consistem em séries temporais coletadas a 10~Hz durante tarefas de \textit{pick-and-place}, abrangendo tanto o comportamento normal quanto cenários de falhas simuladas, como colisões (base e braço) e variações de carga. Essa diversidade torna o \textit{dataset} ideal para avaliar a eficácia de técnicas de análise exploratória, pré-processamento e aprendizado de máquina na caracterização de falhas industriais.

\section{Análise de Dados e Feature Engineering}

\subsection{Análise Exploratória dos Dados}

\subsubsection{Análise Exploratória Estrutural}

A análise exploratória estrutural foi conduzida com o objetivo de compreender a organização e os tipos de atributos presentes no conjunto de dados. Para garantir a integridade da avaliação durante as etapas de \textit{feature selection} e modelagem de forma a prevenir a tomada de decisão enviesada e o vazamento de dados, adotou-se uma estratégia de particionamento dos dados a priori. A divisão em subconjuntos de Treino, Validação e Teste foi realizada imediatamente após a coleta. O Conjunto de Validação, composto por 10\% dos dados Normais e 50\% dos dados de Falha (de cada cenário), foi utilizado para a Análise Exploratória de Dados (EDA) e demais etapas subsequentes.

O dataset é composto por séries temporais de sensores inerciais, contendo variáveis numéricas contínuas associadas às medições de acelerômetro, giroscópio e magnetômetro, nos eixos X, Y e Z; uma coluna temporal que representa o instante de coleta de cada amostra e uma variável indicativa da condição de operação do robô, utilizada como rótulo para diferenciar entre comportamento normal e anômalo. Particularmente, os dados anômalos são separados de acordo com o tipo de falha, sendo elas:

\begin{itemize}
  \item Hitting Platform, que lida com colisão contra a plataforma;
  \item Hitting Arm, colisão contra o próprio braço robótico;
  \item Extra Weight, esforço mecânico dado por peso extra;
  \item Earthquake, vibração estrutural externa.
\end{itemize}

Cada observação corresponde a uma leitura dos sensores em um determinado instante de tempo, sendo os dados organizados de forma sequencial. A variável temporal é representada por valores inteiros de alta resolução, indicando registros em escala de nanosegundos, reforçando o caráter temporal do problema. No entanto, com o objetivo de facilitar a interpretação e a análise de integridade temporal, os valores foram convertidos para milissegundos, mantendo a proporcionalidade entre as amostras e reduzindo a magnitude numérica dos registros. 

Durante a análise estrutural, foi identificada a presença de uma coluna textual associada à identificação do sensor, que por apresentar valor constante em todas as observações e não agregar informação discriminativa ao problema de detecção de anomalias, essa variável foi removida do conjunto de dados. Adicionalmente, foi realizada a verificação de duplicidade nos registros temporais, não sendo identificadas amostras com timestamps repetidos, o que indica consistência na indexação temporal das observações.

\subsubsection{Informações básicas}
O conjunto de dados normais analisado é composto por 874.937 amostras e 11 atributos após a etapa inicial de pré-processamento. Todas as variáveis de sensores são numéricas contínuas do tipo \textit{float64}, enquanto a variável alvo é representada por valores inteiros binários. O volume total de memória ocupado por esse dataset é de aproximadamente 73 MB.

Por outro lado, o conjunto de dados anômalos é composto por 49.185 amostras com os 11 atributos contínuos numéricos e a variável alvo binária. Com um volume total de memória de aproximadamente 10MB. Adicionalmente, o dataset possui um atributo \textit{scenario} que indica o tipo de falha a qual esse registro é associado, seguindo a proporção destacada na tabela abaixo.

\begin{table}[h]
\centering
\caption{Quantidade de anomalias por tipo de falha}
\label{tab:quantidade-anomalia-tipo-falha}
\begin{tabular}{llcc}
\hline
\multicolumn{1}{c}{\textbf{Cenário}} & \textbf{Quantidade} & \textbf{Proporção} \\ \hline
Hitting Platform & 14.967 & 0.3043 \\
Hitting Arm & 11.924 & 0.2424 \\
Earthquake & 11.409 & 0.2320 \\
Extra Weight & 10.885 & 0.2213
\end{tabular}
\end{table}

\subsubsection{Análise de Duplicatas, Valores Faltantes e \textit{Outliers}}
A integridade dos dados foi avaliada sob três perspectivas: redundância de registros, continuidade temporal e presença de valores extremos.

\paragraph{Duplicatas e Valores Nulos Explícitos}
Uma varredura inicial no conjunto de dados brutos não identificou linhas duplicadas ou valores nulos (\textit{NaN}) explícitos nas leituras dos sensores, tanto nos dados normais quanto anômalos. O sistema de aquisição registrou continuamente as 9 variáveis do IMU (acelerômetros, giroscópios e magnetômetros) sem falhas de escrita evidentes.

\paragraph{Análise de Continuidade Temporal}
Embora não houvesse \textit{NaNs} no arquivo original, a análise do intervalo entre amostras revelou um problema crítico de integridade temporal. A frequência nominal de coleta, era de 10 Hz (com \textit{Sampling Rate} de 100 ms). No entanto, observou-se um \textit{Jitter} (desvio padrão do intervalo de tempo) relevante de aproximadamente 22 ms, com 429 \textit{Gaps} Temporais significativos variando entre 2 ms e 342 ms, onde essa quantidade de perda de pacotes foi considerada quando o valor do \textit{Gap} foi maior que 2x a média, sendo categorizada como quebra de continuidade.

Para padronizar a frequência e facilitar o janelamento das séries temporais nas etapas seguintes, foi utilizada a técnica de \textit{Resampling}, impondo uma grade temporal rígida de 100 ms, conforme detalhado na seção de Pré-Processamento dos Dados. Nesse contexto, a irregularidade original foi exposta sob a forma de \textit{Gaps} temporais. No conjunto de dados Normal, o alinhamento gerou cerca de 44.766 lacunas onde não havia dados registrados no timestamp esperado.


\paragraph{Análise de \textit{Outliers}}
A análise de distribuição, por meior de Boxplots e Histogramas, detectou uma quantidade massiva de \textit{outliers} estatísticos, especialmente nos eixos do acelerômetro. Nos dados de colisão (\textit{Hitting Arm}), a curtose do eixo Z atingiu valores extremos ($>100$), com picos de aceleração de até 10g, muito superiores à faixa média normal de operação ($\pm 1g$). Entretenato, diferente de problemas de regressão clássicos, onde \textit{outliers} são ruídos a serem removidos, neste projeto eles constituem o próprio \textbf{sinal de interesse} (a falha mecânica).
\subsubsection{Análise Univariada} \label{subsec:analise-univariada}
Para determinar a sensibilidade individual de cada sensor aos diferentes modos de falha, conduziu-se uma análise estatística univariada comparativa entre a distribuição dos dados no estado Normal e em cada cenário de anomalia. O objetivo foi quantificar o poder discriminatório de cada eixo do IMU, buscando compreender como a distribuição de cada sensor se comporta diante da mudança para um estado de falha e validar a seleção de \textit{features} para a modelagem.

A divergência entre as distribuições foi avaliada utilizando duas métricas complementares:

\begin{itemize}
    \item Teste Kolmogorov-Smirnov (KS-Statistic)}
    \item Razão de Variância ($\sigma^2_{ratio}$)
\end{itemize}


As Tabelas e Figuras abaixo resumem os sensores mais críticos identificados para cada cenário.

\begin{table}[h]
\centering
\caption{Hitting Platform}
\label{tab:stats-hitting-platform}
\begin{tabular}{lccc}
\hline
\multicolumn{1}{c}{\textbf{Sensor}} & \textbf{KS Statistic} & \textbf{Variance Ratio} \\ \hline
accZ & 0.721 & 3.254 \\
magZ & 0.292 & 1.022 \\
accX & 0.242 & 1.032 \\
magY & 0.152 & 1.002 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{imagens/hitting_platform_accZ.png}
\end{figure}

Nas falhas de \textit{Hitting Platform}, o acelerômetro vertical (\texttt{accZ}) consolidou-se como o indicador primário de anomalia, apresentando um KS-Statistic de 0,72 e um aumento de mais de 3 vezes na variância do sinal. Este comportamento reflete a natureza física do evento, um impacto abrupto contra a superfície rígida tende a gerar desacelerações impulsivas de alta magnitude que não alteram significativamente a média global do movimento, mas expandem drasticamente a dispersão dos dados momentâneos.

\begin{table}[h]
\centering
\caption{Hitting Arm}
\label{tab:stats-hitting-arm}
\begin{tabular}{lccc}
\hline
\multicolumn{1}{c}{\textbf{Sensor}} & \textbf{KS Statistic} & \textbf{Variance Ratio} \\ \hline
accZ & 0.740 & 3.279 \\
magY & 0.306 & 0.993 \\
magZ & 0.306 & 1.088 \\
accX & 0.301 & 1.139 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{imagens/hitting_arm_accZ.png}
\end{figure}

O cenário de \textit{Hitting Arm} exibiu uma assinatura estatística semelhante à colisão na plataforma, com o \texttt{accZ} liderando a detectabilidade (KS≈0,74). Contudo, observou-se uma contaminação cruzada mais acentuada nos eixos laterais e nos magnetômetros (ex: \texttt{magY} e \texttt{accX} com KS≈0,30), sugerindo que o choque interno induz vibrações multidirecionais e distorções na orientação magnética momentânea superiores às de um impacto simples.

\begin{table}[h]
\centering
\caption{Earthquake}
\label{tab:stats-earthquake}
\begin{tabular}{lccc}
\hline
\multicolumn{1}{c}{\textbf{Sensor}} & \textbf{KS Statistic} & \textbf{Variance Ratio} \\ \hline
accZ & 0.491 & 22.402 \\
magX & 0.394 & 0.937 \\
magY & 0.303 & 0.972 \\
magZ & 0.274 & 0.946 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{imagens/earthquake_accZ.png}
\end{figure}

A anomalia de \textit{Earthquake} revelou o caso mais extremo de alteração. Embora o KS-Statistic do \texttt{accZ} seja moderado (0,49), indicando que as médias das distribuições não se afastaram radicalmente, a Razão de Variância atingiu um valor crítico de 22,4. Isso indica que a falha não se manifesta por deslocamento de trajetória, mas pela injeção massiva de ruído de alta frequência no sistema, transformando a distribuição normal em uma curva extremamente achatada e espalhada. \\

\begin{table}[h]
\centering
\caption{Extra Weight}
\label{tab:stats-extra-weight}
\begin{tabular}{lccc}
\hline
\multicolumn{1}{c}{\textbf{Sensor}} & \textbf{KS Statistic} & \textbf{Variance Ratio} \\ \hline
accZ & 0.752 & 0.776 \\
magX & 0.400 & 0.927 \\
magY & 0.314 & 0.968 \\
magZ & 0.281 & 0.943 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{imagens/extra_weight_accZ.png}
\end{figure}

Diferentemente dos cenários de impacto e vibração, a falha por \textit{Extra Weight} apresentou um fenômeno de amortecimento dinâmico. O sensor \textit{accZ} manteve a maior separabilidade estatística (KS≈0,75), mas a variância do sinal sofreu uma redução. Fisicamente, isso sugere que o esforço adicional para sustentar a carga limitou a liberdade de oscilação natural do braço (efeito de rigidez), criando uma assinatura de falha caracterizada pela tensão e menor dispersão em torno da trajetória nominal, oposta ao comportamento das colisões.
\subsubsection{Análise Bivariada}

A análise bivariada partiu da hipótese de que a ocorrência de anomalias afeta o estado físico do robô, questionou-se se as falhas seriam capazes de "quebrar" o acoplamento mecânico entre sensores redundantes ou se as alterações seriam mais perceptíveis em pares de baixa correlação. Para investigar essa premissa, foram definidos cenários analíticos estratégicos, cujo objetivo foi garantir que diferentes tipos de relação entre sensores fossem explicitamente investigados. Essa escolha é importante porque pares de variáveis com comportamentos distintos (alta correlação, correlação média ou baixa correlação) tendem a responder de maneira diferente à introdução de falhas, fornecendo evidências complementares sobre a dinâmica do sistema. A métrica utilizada para quantificar a divergência entre as distribuições do alvo normal e anômalo foi a distância de Jensen-Shannon.

Foram definidos seis cenários bivariados. Nos dois cenários de redundância (pares com maior correlação física), a importância reside em avaliar sensores fortemente acoplados. Nesses casos, observou-se que, mesmo na presença de falhas, o padrão conjunto se mantém relativamente estável. Quantitativamente, isso se traduziu nas menores distâncias estatísticas observadas: o par (accx,accy) apresentou uma distância JS de apenas 0.12, seguido pelo par (accy,gyroy) com 0.14. Esses baixos valores indicam que falhas nem sempre rompem relações altamente correlacionadas, sugerindo que pares muito redundantes carregam informação similar e tendem a variar de forma conjunta, mesmo em condições anômalas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/redundancia.png}
\end{figure}

O cenário de linha de base, definido por um par com correlação próxima à média do sistema, foi incluído para representar um comportamento típico. O par (accx,magx) com uma distância JS de 0.20, ilustra essa referência. Esse valor intermediário permite avaliar como a resposta observada em cenários extremos de fato se diferencia do comportamento esperado em uma interação padrão entre sensores.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/diferentes.png}
\end{figure}

Já no cenário de complementaridade, composto por sensores pouco correlacionados entre si, observou-se a mudança mais pronunciada entre os dados normais e de falha. A baixa correlação implica que cada sensor responde a aspectos diferentes do fenômeno físico. Quando ocorre uma falha, essas respostas divergentes ampliam drasticamente a separação entre as distribuições conjuntas. Isso ficou evidente nos pares: (accz,magz) atingiu a maior distância registrada (0.61). Esse alto valor confirma que a combinação de variáveis complementares é a mais sensível para capturar a divergência estatística introduzida pelas anomalias.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/top2.png}
\end{figure}

Por fim, os dois cenários de poder preditivo concentraram-se nos sensores mais correlacionados com o rótulo de falha. A importância desses cenários está em avaliar se sensores individualmente informativos também apresentam mudanças relevantes quando analisados em conjunto. Os resultados indicaram que a introdução de falhas altera a densidade conjunta, embora de forma menos extrema que na complementaridade, ou seja, o que importa não é unicamente a importância do sensor, mas também sua correlação para definir se o par vai se comportar de maneira mais parecida ou não.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/media.png}
\end{figure}

Em suma, a análise validou a hipótese inicial: pares altamente correlacionados tendem a mascarar a anomalia, enquanto pares com baixa correlação evidenciam as alterações de forma mais clara.

\subsubsection{Análise Multivariada}

Na análise multivariada, todas as variáveis dos sensores foram consideradas simultaneamente por meio do PCA (Principal Component Analysis), após padronização. A projeção nos dois primeiros componentes revelou que as anomalias não são facilmente separáveis dos dados normais. As amostras de falha aparecem cercadas por pontos normais e distribuídas em diferentes regiões do espaço reduzido, indicando que não existe um único padrão geométrico simples que caracterize todas as falhas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/biplot.png}
\end{figure}

Apesar dessa sobreposição, a visualização evidenciou diferenças estruturais relevantes. Em diversas regiões do espaço PCA, observam-se concentrações de falhas com orientações e dispersões distintas, refletindo o impacto específico de cada tipo de anomalia sobre o sistema. Isso indica que, embora não haja separação linear clara, as falhas alteram a dinâmica multivariada de maneira consistente, produzindo padrões locais diferenciados.

As setas do biplot permitiram interpretar a contribuição de cada sensor para essas diferenças, destacando quais variáveis influenciam mais fortemente determinadas direções do espaço PCA. Sensores com vetores mais extensos tiveram maior peso na organização dos dados, ajudando a explicar por que determinadas anomalias se manifestam em regiões específicas do plano.

A análise foi complementada pela visualização temporal de janelas de 30 segundos no espaço PCA, utilizando uma régua visual fixa para todos os cenários. Essa abordagem evidenciou que o comportamento normal tende a produzir trajetórias mais compactas e regulares, enquanto os cenários de falha apresentam trajetórias mais dispersas e irregulares, reforçando o impacto dinâmico das anomalias ao longo do tempo.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/temporal.png}
\end{figure}

No que se refere às variáveis derivadas, foram calculadas magnitudes físicas da aceleração, do giroscópio e do magnetômetro, com o objetivo de condensar informações multieixo em medidas escalares fisicamente interpretáveis. 

Testes exploratórios básicos, como a comparação de distribuições entre classes e análises de separação estatística, indicaram que essas variáveis capturam alterações relevantes introduzidas pelas falhas, mostrando potencial para uso na otimização dos modelos subsequentes, permitindo, por exemplo, estratégias de redução de dimensionalidade que mantenham a interpretabilidade física do fenômeno ao diminuir o número de variáveis de entrada.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/importancia.png}
\end{figure}

Por fim, aplicou-se o K-Means para identificar grupos de interesse no espaço formado pelas variáveis originais. O uso de um método não supervisionado é adequado nesse contexto, pois permite investigar a estrutura intrínseca dos dados sem recorrer aos rótulos. Os resultados mostraram que, considerando apenas os dados brutos, não foi possível identificar um grupo claramente dominante em termos de concentração de falhas.

\begin{table}[H]
    \centering
    \begin{tabular}{c c c}
        \hline
        \textbf{Cluster} & \textbf{Normal (\%)} & \textbf{Falha (\%)} \\
        \hline
        0 & 96.601872 & 3.398128 \\
        1 & 96.528435 & 3.471565 \\
        2 & 96.646539 & 3.353461 \\
        \hline
    \end{tabular}
\end{table}


\subsection{Pré-processamento dos dados}
Apresentar ações referentes ao pré-processamento de dados a exemplo de:

\subsubsection{Tratamento de Valores Faltantes}

Para corrigir os problemas de  \textit{timestamps} irregularmente espaçadas e amostras faltantes, sem descartar dados, optou-se pela \textbf{interpolação linear} dos valores faltantes gerados pelo \textit{Resampling}. Essa abordagem preservou a tendência do movimento entre os pontos conhecidos, restaurando a continuidade necessária para a extração de \textit{features} de janela deslizante.

Para os conjuntos de dados anômalos, a etapa de regularização temporal com \textit{Resampling} e Interpolação foi aplicada de forma iterativa e independente para cada cenário de falha, ao invés da aplicação direta sobre o conjunto anômalo completo. Essa abordagem foi necessária para prevenir as descontinuidades temporais, visto que os experimentos de falha foram registrados em contextos diferentes e com \textit{Gaps} de minutos a horas entre si e a imposição de uma grade temporal contínua de 10Hz no dataset completo forçaria a criação de milhares de linhas vazias para preencher esses intervalos e a interpolação linear geraria dados sintéticos falsos, o que tornaria inviável alimentar o modelo com esses dados, mesmo com etapas subsequentes de pré-processamento.


\subsubsection{Tratamento de Outliers e Feature Scaling}
Conforme detalhado anteriormente, os \textit{outliers} identificados representam uma parte importante do problema e representam medições verossímeis. Consequentemente, optou-se por \textbf{não removê-los}. No entanto, tendo em mente a fonte dos dados e a natureza dos sensores, foi necessário aplicar um filtro para reduzir o ruído dos sinais, sendo utilizado o Savitzky-Golay, que ajusta polinômios localmente, por sua capacidade de preservar melhor a forma e pico dos sinais que outros baseados em médias rolantes.
Adiconalmente, para mitigar o impacto desses valores extremos do sensores na normalização dos dados, substituiu-se o \textit{StandardScaler} (sensível à média/desvio padrão) pelo \textbf{\textit{RobustScaler}}, sendo este ajustado somente ao conjunto de treinamento dos dados normais e posteriormente usado para transformar os outros conjuntos. Este escalonador utiliza a mediana e o intervalo interquartil (IQR), garantindo que os picos de colisão permaneçam destacados na escala transformada, preservando a assinatura da anomalia para o modelo. 


\subsubsection{Detecção e Tratamento de Duplicadas}
Não havia duplicadas no \textit{dataset}, devido ao processo de geração deste dataset. 


\subsubsection{Encoding de Variáveis Categóricas}
Os dados não contém qualquer variável categórica, sendo desnecessárias estratégias de \textit{encoding}.

\subsection{Divisão dos Dados}
Os dados normais, não-anomalos, conforme ilustrado em \ref{tab:dataSplit}, foram dividos em 60\%, 20\% e 20\% entre os conjuntos de treinamento, validação e teste, respectivamente, enquanto foi dividido em 50\% para a validação e 50\% para o conjunto de testes. Em ambos os casos, a divisão respeitou a ordenação dos dados ao longo do tempo, visando evitar o vazamento de informações e a violação das relações temporais entre os pontos de dados.

Além disso, no caso dos dados anômalos, foi feita divisão estratificada, para garantir que cada classe de anomalia, que ocorreram cada uma independentemente e não concomitantemente, como os choques na plataforma e os choques no braço robótico, estivessem proporcionalmente representadas nos conjuntos de validação e teste.

\begin{table}[htbp]
    \centering
    \caption{Divisão Percentual dos Conjuntos de Dados)}
    \label{tab:dataSplit}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Conjunto de Dados} & \textbf{Treino (\%)} & \textbf{Validação (\%)} & \textbf{Teste (\%)} \\
        \hline
        Normal & 60,0 & 20,0 & 20,0 \\
        \hline
        Anomalia & 0,0 & 50,0 & 50,0 \\
        \hline
    \end{tabular}
    \vspace{-1mm} % Ajuste de espaçamento, se necessário
\end{table}

\subsection{Feature Engineering}
A estratégia de engenharia de atributos (\textit{Feature Engineering}) adotada neste trabalho foi adaptada aos diferentes de tipos de modelos avalaidos. Processo de extração manual de atributos  foi aplicado \textbf{exclusivamente} aos modelos probabilísticos e baseados em densidade (Isolation Forest, Gaussian Mixture Models).

Para as abordagens baseadas em Deep Learning, foram usados os dados brutos das séries temporais, submetidos apenas à criação de janelas, considerando a capacidade dessas arquiteturas de fazer (\textit{representation learning}) e capturar dependências temporais complexas. Em contrapartida, os modelos clássicos carecem da habilidade nativa de interpretar a sequencialidade temporal de alta dimensão dos sensores brutos (90 dimensões por segundo de janela) tornando imperativa a transformação desses dados em vetores de estatísticas descritivas que sintetizem o comportamento dinâmico e espectral do robô.

Dessa forma, o \textit{pipeline} de engenharia de atributos para os modelos clássicos foi feito em três etapas: Criação de janelas, extração e seleção, conforme detalhado a seguir.

\subsubsection{Criação de janelas}
Para a criação de janelas, foram utilizadas janelas móveis (\textit{sliding windows}), que possuem uma intercessão ajustável com as janelas imediatamente vizinhas Um algoritmo ilustrativo para a criação de janelas deslizantes esa descrito em \ref{alg:sliding_window}.

Cada parte dos dados passou por esse processo isoladamente, e janelas incompletas foram descartadas para garantir a uniformidade das matrizes resultantes. Por exemplo, visto que a frequência de coleta de dados foi de 10Hz, uma janela de 40 amostras captura 4 segundos de funcionamento do braço robótico. Ademais, os parâmetros das janelas foram considerados como hiperparâmetros na etapa da modelagem, para que sejam escolhidos otimamente. Esta escolha é muito importante, porque o tamanho da janela depende muito dos modelos, e os eventos de interesse são muitos particulares do problema. No caso desse dataset, observamos que os eventos de interesse de fato exigiam uma análise um período de alguns segundos.
\begin{algorithm}
\caption{Segmentação em Janelas Deslizantes (Sliding Windows)}\label{alg:sliding_window}
\begin{algorithmic}
\Require $D$ (Dados $N \times F$), $L$ (Tamanho da Janela), $O$ (Overlap)
\Ensure $\mathcal{W}$ (Tensor de janelas $M \times L \times F$)

\State $S \gets L - O$
\State $N \gets \text{rows}(D)$
\State $\mathcal{W} \gets \emptyset$ 
\State $i \gets 0$

\While{$i + L \leq N$}
    \State $w \gets D[i : i + L, :]$ 
    \State $\mathcal{W} \gets \mathcal{W} \cup \{w\}$ 
    \State $i \gets i + S$ 
\EndWhile

\State \Return $\mathcal{W}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Extração e seleção de features}
Nesta etapa, buscamos transformar os sinais dos sensores em uma representação mais informativa, bem como adaptá-la às limitações dos modelos que não usam Deep Learning  usados neste trabalho, que não lidam bem com a grande quantidade de dimensões envolvida e com a alta correlação entre features. Esse processo se dividiu entre a extração e a seleção de features.

Inicialmente, fizemos a extração de features a nível de amostra. A partir dos sinais originais, criamos variáveis derivadas utilizando a interpretação física do problema e do que cada varíavel representava, como a norma vetorial de cada sensor, que captura a magnitude total da mudança por ele registrada, unindo os eixos.

Em seguida, os sinais e seus atributos derivados foram segmentados em janelas como descrito a cima. Para cada janela, foram extraídas estatísticas agregadas calculadas exclusivamente com as \textit{features} originais, agregando tendências e informações sobre o periodo inteiro de tempo representado pelo tamanho da janela.
\begin{enumerate}
    \item \textbf{Média:} representa o valor médio do sinal ao longo da janela e está associada ao nível basal ou tendência local do movimento. Alterações na média podem indicar mudanças sistemáticas no comportamento do sistema, como inclinações persistentes ou deslocamentos contínuos.
    
    \item \textbf{Desvio padrão:} quantifica a variabilidade do sinal dentro da janela, sendo fortemente associado à intensidade de vibrações.
    
    \item \textbf{RMS (Root Mean Square):} mede a energia total do sinal, combinando informações de magnitude e variabilidade. Diferentemente da média, o RMS é sensível tanto a oscilações quanto a impactos.
    
    \item \textbf{Pico-a-pico (peak-to-peak):} corresponde à diferença entre os valores máximo e mínimo do sinal na janela, tambem capturando grandes variações.
    
    \item \textbf{Curtose:} caracteriza o grau de impulsividade do sinal, indicando a presença de picos abruptos e eventos raros de grande magnitude..
    
    \item \textbf{Fator de crista (crest factor):} definido como a razão entre o valor de pico e o RMS, fornece uma medida normalizada da severidade dos picos em relação à energia média do sinal. Essa \textit{feature} é especialmente útil para diferenciar vibrações contínuas de impactos pontuais.
    
    \item \textbf{Frequência dominante:} extraída a partir da transformada de Fourier da janela, indica a frequência com maior energia espectral. Essa informação permite capturar características dinâmicas do sistema, como ressonâncias, mudanças de regime de operação ou vibrações induzidas por cargas externas.
\end{enumerate}

Essas \textit{features} sintetizam muitas propriedades fundamentais do comportamento do sinal dentro da janela e constituem uma representação comparativamente compacta desse comportamento. Dessa forma, ao invés de termos um total de \(features*tamanhoDaJanela\) dimensões, ou seja, 360, no caso dos nossos 9 sensores e uma janela de 40 amostras, obtemos apenas 72 dimensões.

No entanto, apesar de representar uma redução considerável da dimensionalidade, essas \textit{features} ainda podem apresentar elevada redundância estatística. Em particular, muitas das estatísticas extraídas descrevem aspectos relacionados do sinal (por exemplo, desvio padrão, RMS e pico-a-pico), o que resulta em fortes correlações lineares entre atributos. A presença desse tipo de redundância pode prejudicar o desempenho de modelos probabilísticos e baseados em densidade, além de aumentar o custo computacional e dificultar a interpretação dos resultados.

Dessa forma, foi aplicada uma etapa explícita de seleção de \textit{features}. Inicialmente, realizou-se uma análise de correlação linear entre os atributos extraídos, utilizando o coeficiente de correlação de Pearson. Para cada par de \textit{features} cuja correlação absoluta excedia um limiar de 0,95, apenas uma delas foi mantida. Essa estratégia visa eliminar atributos altamente redundantes, preservando, ao mesmo tempo, a maior diversidade possível de informações relevantes. Após essa etapa, o número de \textit{features} foi reduzido de 72 para 58.

Mesmo após a remoção de correlações elevadas, o espaço de atributos ainda permanecia relativamente grande e com possíveis dependências lineares de ordem superior. Assim, aplicou-se uma etapa adicional de redução de dimensionalidade por meio da Análise de Componentes Principais (PCA). O PCA foi ajustado exclusivamente sobre o conjunto de treinamento, após normalização robusta dos dados, e o número de componentes foi selecionado de forma a preservar pelo menos 95\% da variância total dos dados. Como resultado, o espaço de atributos foi reduzido de 58 para 15 componentes principais, mantendo uma variância explicada acumulada de aproximadamente 95,28%.

Essa combinação de seleção por correlação e redução via PCA permitiu obter uma representação compacta, pouco redundante e estatisticamente bem condicionada dos dados, adequada às premissas dos modelos clássicos avaliados neste trabalho. Além disso, ao concentrar a maior parte da variabilidade dos sinais em um número reduzido de componentes, essa abordagem contribui para maior estabilidade numérica, melhor generalização e menor sensibilidade a ruído.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/variancia.png}
\end{figure}



\section{Modelagem}
Três modelos foram escolhidos para esse projeto: Gaussian Mixture Model (GMM), Isolation Forest e Autoencoder Convolucional. Todos os modelos condizem com o problema proposto: são próprios para aprendizado não-supervisionado, cada um possuindo uma abordagem distinta para tanto: clustering, isolamento e aprendizado profundo baseado em redes neurais, respectivamente, tornando-os apropriados para comparar a eficácia desses diferentes métodos para o dataset em questão. O processo de seleção de modelos utilizou como métrica principal a AUC. No entanto, devido ao uso de predições binárias em vez de escores contínuos, essa métrica não corresponde estritamente à AUROC tradicional, funcionando como uma medida de desempenho baseada em classificação após a aplicação de um limiar
\subsection{Gaussian Mixture Model}
\subsubsection{Conceitos Básicos} O modelo de mistura gaussiana (gaussian mixture model, GMM) é um modelo probabilístico que assume que os dados são descritos por uma mistura de distribuições gaussianas.

Formalmente, um GMM modela a densidade de probabilidade de uma observação
$\mathbf{x} \in \mathbb{R}^d$ como uma soma ponderada de $K$ componentes Gaussianos,
dada por:

\begin{equation}
p(\mathbf{x}) = \sum_{k=1}^{K} \pi_k \, \mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k),
\end{equation}

onde $\pi_k$ representa o peso da $k$-ésima componente, satisfazendo
$\sum_{k=1}^{K} \pi_k = 1$, e $\boldsymbol{\mu}_k$ e $\boldsymbol{\Sigma}_k$ correspondem,
respectivamente, ao vetor de médias e à matriz de covariância da componente $k$. Os parâmetros são encontrados por meio da maximização de expectativa, alternando entre momento de estimação das probabilidades e atualização dos parâmetros.

O GMM é um algoritmo de soft clustering, ou seja, atribui probabilidades ao invés de classificar unicamente a um dos componentes, tornando-o mais robusto. Serão classificadas como anomalias os dados que possuam baixa probabilidade (log-verossimilhança).
\subsubsection{Justificativa} O GMM foi escolhido primeiramente por ser um modelo de clustering, uma das abordagens mais importantes para aprendizagem não-supervisionada. Entre os algoritmos desse tipo, o GMM se destaca por utilizar o soft clustering probabilistico e modelar os grupos com base em multiplas distribuições, lidando bem com dados mais complexos. 

Por fim, o GMM apresenta uma boa relação entre expressividade e custo computacional, sendo capaz de modelar correlações entre variáveis (por meio de matrizes de covariância completas) sem exigir grandes volumes de dados ou recursos computacionais elevados. Dessa forma, o GMM se configura como uma escolha sólida e complementar aos modelos de isolamento e aprendizado profundo considerados neste trabalho, contribuindo para uma comparação abrangente entre diferentes paradigmas de detecção de anomalias aplicados ao dataset em questão.
\subsubsection{Espaço de Busca} Para a tunagem foi utilizado o grid search. Os parâmetros buscados para descobrir o melhor número de componentes foram limitados a números baixos devido à natureza do problema: o braço robótico, que deve seguir movimentos repetitivos em condições normais, não precisará de muitos clusters, como foi verificado pelo seu melhor parâmetro.
\begin{table}[ht]
\centering
\caption{Espaço de busca dos hiperparâmetros utilizados na tunagem do modelo Gaussian Mixture Model (GMM).}
\label{tab:gmm_search_space}
\begin{tabular}{ll}
\hline
\textbf{Categoria} & \textbf{Hiperparâmetro e valores considerados} \\
\hline
\multirow{2}{*}{Janelamento} 
& (\texttt{new\_window\_size}): \{30, 60\} \\
& (\texttt{window\_overlap}): \{0, 15\} \\
\hline
\multirow{4}{*}{GMM}
& (\texttt{n\_components}): \{1, 2, 3, 4\} \\
& (\texttt{covariance\_type}): \{\texttt{diag}, \texttt{full}\} \\
& (\texttt{reg\_covar}): \{1e{-}5\} \\
& (\texttt{threshold\_percentile}): \{1, 2.5, 5\} \\
\hline
\end{tabular}
\end{table}
\subsubsection{Hiperparâmetros Selecionados} Para a janela, o melhor foi com tamanho 60 e overlap 0. Para o modelo, foi 1 componente, tipo de covariância 'diag' e limiar 1.
\subsection{Isolation Forest}
\subsubsection{Conceitos Básicos} O Isolation Forest é um modelo de aprendizagem não-supervisionada bastante relacionado com detecção de anomalias. Diferentes de outros modelos que também são frequentemente usados para essa área, o Isolation Forest utiliza o princípio de isolamento, isto é, dado que anomalias devem ser bem diferenciáveis dos dados normais, elas serão mais fáceis de isolar com um particionamento aleatório.

O algoritmo constrói um conjunto de árvores binárias, denominadas isolation trees, nas quais cada nó interno realiza uma divisão aleatória escolhendo um atributo e um valor de corte também aleatório dentro do intervalo observado desse atributo. O processo continua recursivamente até que a instância seja isolada em um nó folha ou até que seja atingida uma profundidade máxima.

Para definir se um dado é anômalo ou não, o modelo utiliza o comprimento médio do caminho, ou seja, a profundida média necessária para isolá-lo. O anomaly score gerado parte do princípio que dados anômalos serão isolados mais cedos que os demais.
\subsubsection{Justificativa} Primeiramente, esse modelo foi projetado precisamente para problemas como o nosso: não-supervisionado, com detecção de anomalias raras, e utiliza uma abordagem diferente da dos outros modelos escolhidos. 

Além disso, ele funciona como um bom contraponto para o clustering previamente testado: datasets como o que usamos, relacionado à sensores industriais, costumam ter muitas dimensões, especialmente com o janelamento temporal, o que impacta negativamente modelos como K-Means e GMM, a chamada "maldição da dimensionalidade". Por não depender de métricas de distância globais, o Isolation Forest evita esse problema. O cárater aleatório e de ensemble dele também auxilia na detecção de anomalias de vários tipos, como é o caso desse dataset.
\subsubsection{Espaço de Busca} a tunagem foi feita utilizando o tradicional método de grid search, testando todas as combinações dos parâmetros possíveis detalhados na tabela. 
\begin{table}[ht]
\centering
\caption{Espaço de busca dos hiperparâmetros utilizados na tunagem do modelo Isolation Forest.}
\label{tab:isoforest_search_space}
\begin{tabular}{ll}
\hline
\textbf{Categoria} & \textbf{Hiperparâmetro e valores considerados} \\
\hline
\multirow{2}{*}{Janelamento} 
&(\texttt{new\_window\_size}): \{30, 60\} \\
& (\texttt{window\_overlap}): \{0, 15\} \\
\hline
\multirow{3}{*}{Isolation Forest}
& (\texttt{n\_estimators}): \{50, 100, 150, 200, 250, 300\} \\
&(\texttt{max\_samples}): \{\texttt{auto}, 0.25, 0.5, 0.75\} \\
& (\texttt{contamination}): \{\texttt{auto}, 0.01, 0.05, 0.1\} \\
\hline
\end{tabular}
\end{table}
\subsubsection{Hiperparâmetros Selecionados} para a janela, o tamanho e o overlap foram 60 e 15, respectivamente. No modelo, os melhores parâmetros foram 50 àrvores, 0.75 fração de amostras por árvore e taxa de contaminação automática ('auto').
\subsection{Autoencoder Convolucional}
\subsubsection{Conceitos Básicos} 
Autoencoders são modelos de aprendizado não supervisionado baseados em redes neurais artificiais cujo objetivo é aprender uma representação compacta dos dados por meio da reconstrução da entrada. Formalmente, um autoencoder é composto por duas funções principais: um codificador, que projeta os dados de entrada em um espaço latente de menor dimensionalidade, e um decodificador, responsável por reconstruir os dados originais a partir dessa representação comprimida. O treinamento é realizado minimizando uma função de perda de reconstrução, tipicamente o erro quadrático médio (MSE), entre a entrada e sua reconstrução.

No caso de Autoencoders Convolucionais 1D, camadas densas são substituídas por camadas convolucionais unidimensionais, que exploram explicitamente a estrutura temporal ou sequencial dos dados. As convoluções 1D aplicam filtros locais ao longo do eixo temporal, permitindo ao modelo capturar padrões de curto alcance, como tendências locais, transições abruptas e correlações temporais entre variáveis sensoriais, auxiliado por operações como pooling e upsampling, permitindo reduzir e recuperar as representações.

Para detecção de anomalias, o autoencoder é treinado exclusivamente com dados considerados normais, aprendendo a reconstruir adequadamente padrões recorrentes do comportamento normal, enquanto apresenta maior erro de reconstrução para amostras divergentes. Assim, o erro de reconstrução passa a ser utilizado como uma métrica contínua de anomalia, permitindo a definição de um limiar para classificação.
\subsubsection{Justificativa}
A escolha de um Autoencoder Convolucional 1D para este projeto se justifica principalmente pela natureza temporal e multivariada dos dados analisados. Diferentemente de métodos baseados apenas em distribuição estatística ou isolamento geométrico, autoencoders convolucionais são capazes de aprender relações não lineares complexas entre múltiplos sensores ao longo do tempo, sem a necessidade de rótulos explícitos. Além disso, o uso de convoluções 1D confere ao modelo invariância local e capacidade de generalização, algo muito valioso em ambientes que podem ter ruído.

É um modelo bastante robusto, baseado em aprendizagem profunda, capaz de modelar relações complexas e altamente não-lineares.  

Por fim, a abordagem baseada em erro de reconstrução permite uma separação clara entre dados normais e anômalos, como evidenciado pelos resultados experimentais obtidos neste trabalho, nos quais as anomalias apresentaram erros de reconstrução significativamente superiores aos observados em dados normais. Essa característica torna o Autoencoder Convolucional uma ferramenta eficaz e robusta para detecção de anomalias em séries temporais multivariadas.
\subsubsection{Espaço de Busca} Foi feito um grid search para tunagem de hiperparâmetros. Antes da tunagem propriamente dita, diversas arquiteturas foram analisadas manualmente para delimitar nosso espaço de busca, evitando uma grid search muito extensa e demorada, testando configurações mais complexas e com mais camadas, chegando até a 64 filtros. No entanto, elas apresentaram resultados semelhantes a arquiteturas mais simples de cerca de 8 filtros. Para evitar overfitting e custo computacional elevado, optamos pelos parâmetros abaixo.
\begin{table}[ht]
\centering
\caption{Espaço de busca dos hiperparâmetros utilizados na tunagem do Autoencoder Convolucional 1D.}
\label{tab:ae_search_space}
\begin{tabular}{ll}
\hline
\textbf{Categoria} & \textbf{Hiperparâmetro e valores considerados} \\
\hline
\multirow{5}{*}{Autoencoder Convolucional 1D}
& (\texttt{filters}): \{\{8,8\}, \{8,6\}, \{12,8\}\} \\
& (\texttt{kernel\_sizes}): \{\{3,3\}, \{5,3\}\} \\
& (\texttt{latent\_channels}): \{4, 8\} \\
& (\texttt{batch\_size}): \{64\} \\
& (\texttt{epochs}): \{60\} \\
& (\texttt{lr}): \{$10^{-3}$\} \\
& (\texttt{patience}): \{5\} \\
& (\texttt{percentile}): \{95.0, 97.5, 99\} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Hiperparâmetros Selecionados}
A janela tem tamanho 60 com overlap 15. Para o modelo, tem duas camadas convolucionais com 8 e 6 filtros, respectivamente e 5 e 3 de tamanho de kernel, 4 canais no espaço latente e threshold de 99.  
\section{Análise e Comparação de Resultados}
\begin{table}[ht]
\centering
\caption{Resultados de desempenho do modelo Gaussian Mixture Model (GMM) no conjunto de teste.}
\label{tab:gmm_results}
\begin{tabular}{|l|c|}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Acurácia (Accuracy) & 0.8256 \\
Precisão (Anomalia como positiva) & 0.1899 \\
Revocação (Recall – Anomalia) & 1.0000 \\
F1-score (Anomalia) & 0.3192 \\
ROC AUC & 1.0000 \\
PR AUC (Average Precision) & 1.0000 \\
Média de log-verossimilhança (normal) & -1672.9433 \\
Média de log-verossimilhança (anômalo) & -12554031.9700 \\
\hline
\end{tabular}
\end{table}
\begin{table}[ht]
\centering
\caption{Matriz de confusão do modelo Gaussian Mixture Model (GMM) no conjunto de teste.}
\label{tab:gmm_confusion}
\begin{tabular}{|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classe Real}} & \multicolumn{2}{c|}{\textbf{Classe Predita}} \\
\cline{2-3}
 & \textbf{Anomalia} & \textbf{Normal} \\
\hline
\textbf{Anomalia} & 166 & 0 \\
\hline
\textbf{Normal} & 708 & 3186 \\
\hline
\end{tabular}
\end{table}

O Gaussian Mixture Model (GMM) alcançou recall igual a 1,0, detectando todas as anomalias presentes no conjunto de teste, o que evidencia elevada sensibilidade. No entanto, essa capacidade foi acompanhada por um número expressivo de falsos positivos, refletido em uma precisão de aproximadamente 0,19 e em um F1-score de cerca de 0,32, ainda que superior ao obtido pelo Isolation Forest. Apesar desse desempenho binário moderado, as métricas baseadas em ranqueamento revelam um cenário significativamente mais favorável: tanto a ROC AUC quanto a PR AUC atingiram o valor máximo (1,0). Essa discrepância indica que o GMM foi capaz de separar perfeitamente amostras normais e anômalas no espaço de escores contínuos (log-verossimilhança), mas que o limiar adotado para a decisão final não foi ótimo. Tal interpretação é corroborada pela diferença extrema observada entre as log-verossimilhanças médias das amostras normais e anômalas, sugerindo que as anomalias apresentam padrões estatísticos profundamente incompatíveis com a distribuição aprendida a partir dos dados normais.

A escolha do número de componentes igual a um para o melhor GMM reforça essa interpretação. Um modelo unimodal assume que os dados normais podem ser adequadamente descritos por uma única distribuição Gaussiana, tratando desvios significativos como anômalos. Nesse contexto, a excelente separação observada nos scores sugere que o conjunto de dados normal é relativamente homogêneo, enquanto as anomalias representam desvios extremos, o que favorece abordagens baseadas em densidade. Ainda assim, a taxa de falsos positivos indica a necessidade de uma estratégia de calibração de limiar mais criteriosa, por exemplo, baseada na maximização do F1-score ou em restrições de precisão mínima no conjunto de validação.

\begin{table}[ht]
\centering
\caption{Resultados de desempenho do modelo Isolation Forest no conjunto de teste.}
\label{tab:isoforest_results}
\begin{tabular}{|l|c|}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Acurácia (Accuracy) & 0.8579 \\
Precisão (Anomalia como positiva) & 0.1487 \\
Recall – Anomalia & 0.5241 \\
F1-score (Anomalia) & 0.2317 \\
ROC AUC & 0.7745 \\
PR AUC (Average Precision) & 0.3212 \\
\hline
\end{tabular}
\end{table}
\begin{table}[ht]
\centering
\caption{Matriz de confusão do modelo Isolation Forest no conjunto de teste.}
\label{tab:isoforest_confusion}
\begin{tabular}{|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classe Real}} & \multicolumn{2}{c|}{\textbf{Classe Predita}} \\
\cline{2-3}
 & \textbf{Anomalia} & \textbf{Normal} \\
\hline
\textbf{Anomalia} & 87 & 79 \\
\hline
\textbf{Normal} & 498 & 3396 \\
\hline
\end{tabular}
\end{table}

O Isolation Forest apresentou acurácia global de aproximadamente 85,8\%, valor influenciado principalmente pelo forte desbalanceamento entre amostras normais e anômalas. Apesar dessa acurácia relativamente elevada, o modelo obteve baixa precisão para a classe anômala (cerca de 0,15), indicando que a maioria das amostras sinalizadas como anômalas corresponde, na realidade, a padrões normais. Em contrapartida, o recall de aproximadamente 0,52 sugere que o modelo foi capaz de identificar pouco mais da metade das anomalias reais presentes no conjunto de teste. Esse comportamento resulta em um F1-score reduzido (cerca de 0,23), evidenciando um compromisso desfavorável entre sensibilidade e precisão. A métrica ROC AUC de 0,77 indica que, embora o modelo possua capacidade razoável de ranqueamento entre padrões normais e anômalos, sua fronteira de decisão não é suficientemente discriminativa para fornecer decisões binárias confiáveis sem uma calibração adicional do limiar de decisão. Somado à isso, o isolation forest foi o único modelo que classificou algumas anomalias como normais, algo que seria bastante problemático no ambiente de produção.

\begin{table}[ht]
\centering
\caption{Resultados do Autoencoder Convolucional no conjunto de teste.}
\label{tab:autoencoder_results}
\begin{tabular}{lc}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Acurácia & 0.9567 \\
Precisão (anomalia como positiva) & 0.4854 \\
Revocação / Recall (anomalia como positiva) & 1.0000 \\
F1-score (anomalia como positiva) & 0.6535 \\
ROC AUC & 1.0000 \\
PR AUC (Average Precision) & 1.0000 \\
\hline
\end{tabular}
\end{table}
\begin{table}[ht]
\centering
\caption{Matriz de confusão do modelo Autoencoder Convolucional no conjunto de teste.}
\label{tab:isoforest_confusion}
\begin{tabular}{|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Classe Real}} & \multicolumn{2}{c|}{\textbf{Classe Predita}} \\
\cline{2-3}
 & \textbf{Anomalia} & \textbf{Normal} \\
\hline
\textbf{Anomalia} & 166 & 0 \\
\hline
\textbf{Normal} & 176 & 3718 \\
\hline
\end{tabular}
\end{table}

A Tabela de resultados e a matriz de confusão obtidas para o Autoencoder Convolucional evidenciam um desempenho significativamente superior em comparação aos modelos baseados em métodos estatísticos e de isolamento. No conjunto de teste, o modelo alcançou uma acurácia de 95,67\%, a maior de todas, indicando elevada capacidade global de classificação. Além disso, o recall máximo de 1 e a matriz de confusão demonstra a ausência de falsos negativos. Tal resultado é particularmente relevante nos cenários industriais, como discutido.

Em contrapartida, observa-se a presença de 176 falsos positivos, correspondentes a amostras normais classificadas incorretamente como anomalias. Esse fenômeno se reflete em uma precisão para a classe anômala de 48,54\%, indicando que aproximadamente metade das detecções de anomalia corresponde, a padrões normais. O equilíbrio entre precisão e recall é sintetizado pelo F1-score de 0,6535 para a classe anômala, valor substancialmente superior aos observados nos modelos Isolation Forest e GMM. Esse resultado indica que o Autoencoder Convolucional alcança uma relação mais favorável entre sensibilidade e seletividade, mesmo sob forte desbalanceamento dos dados. Os valores máximos obtidos para ROC AUC e Average Precision (ambos iguais a 1,00) evidenciam uma separação praticamente perfeita entre padrões normais e anômalos em termos do erro de reconstrução.


\section{Conclusão e Discussão}

O GMM alcançou ROC AUC e PR AUC perfeitos (1.0), indicando excelente separabilidade entre dados normais e anômalos. Porém, sua precisão foi baixa (0.19), revelando problema de calibração de limiar. A escolha de um único componente sugere que o comportamento normal é homogêneo e as anomalias representam desvios estatísticos claros.

O Isolation Forest apresentou recall de apenas 0.52, deixando metade das anomalias sem detecção. Com precisão de 0.15 e falha em detectar algumas anomalias, seu desempenho se mostrou insatisfatório para um sistema crítico.

O Autoencoder Convolucional 1D operou diretamente nas séries temporais, capturando relações não-lineares sem features pré-computadas. Essa abordagem se mostrou promissora para capturar a dinâmica temporal do robô.

A análise exploratória foi decisiva. Identificar que pares de sensores com baixa correlação apresentavam maior divergência (distância JS 0.61 para accz-magz) guiou a engenharia de features. Preservar outliers como sinal — não ruído — foi correto: picos de 10g caracterizam colisões genuínamente. O pré-processamento com Savitzky-Golay e RobustScaler manteve essa informação intacta.

A redução dimensional (72 $\to$ 15 features) funcionou bem, eliminando redundância sem perder informação crítica. O principal desafio foi o desbalanceamento de classes (49K anomalias vs 875K normais), afetando métricas como F1-score e tornando a seleção de limiar crítica.

Para produção, GMM seria escolha conservadora: fácil de treinar, interpretável, baixo custo computacional. Isolation Forest seria apropriado só se eficiência fosse prioritária. Autoencoder requer mais recursos mas oferece maior robustez. Um ensemble combinando múltiplos modelos provavelmente teria melhor desempenho.

Este trabalho demonstrou viabilidade de técnicas não-supervisionadas para detecção de anomalias em robôs industriais. O sucesso dependeu de análise exploratória rigorosa, pré-processamento especializado e seleção cuidadosa de features, fornecendo toolkit adaptável para diferentes cenários de monitoramento industrial.
% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].

% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\begin{thebibliography}{9}

\bibitem{casper_acm}
H.~Kayan, R.~Heartfield, O.~Rana, P.~Burnap, and C.~Perera,
``CASPER: Context-Aware IoT Anomaly Detection System for Industrial Robotic Arms,''
\emph{ACM Transactions on Internet of Things},
vol.~5, no.~3, art.~18, Aug.~2024, doi: 10.1145/3670414.

\bibitem{percom_realtime}
H.~Kayan, R.~Heartfield, O.~Rana, P.~Burnap, and C.~Perera,
``Real-Time Anomaly Detection for Industrial Robotic Arms Using Edge Computing,''
\emph{2023 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)},
2023.

\bibitem{review_timeseries}
A.~Blázquez-García, M.~S.~Del Aguila, I.~López, P.~López, and F.~Sánchez,
``A review on outlier/anomaly detection in time series data,''
\emph{ACM Computing Surveys},
vol.~54, no.~3, pp.~1--33, 2021.

\bibitem{mahalanobis_svdd}
Y.~Yang et al.,
``Unsupervised Anomaly Detection for Autonomous Robots via Mahalanobis SVDD with Audio-IMU Fusion,''
\emph{arXiv preprint arXiv:2505.05811},
2025.

\bibitem{chirayil_anomaly}
S.~Chirayil Nandakumar et al.,
``Anomaly detection methods in autonomous robotic missions,''
\emph{Sensors},
vol.~24, no.~4, p.~1330, 2024.
\bibitem{windows}
Keogh, E., Lin, J. Clustering of time-series subsequences is meaningless: implications for previous and future research. \emp{Knowl Inf Syst 8}, 154–177 (2005).
\bibitem{windows}
Keogh, E., Lin, J. Clustering of time-series subsequences is meaningless: implications for previous and future research. \emp{Knowl Inf Syst 8}, 154–177 (2005).

\end{thebibliography}




% that's all folks
\end{document}