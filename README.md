# Anomaly Detection in Industrial Robotic Arms
**Sumary**
A work that analyzed the Casper Industrial Robotic Arm dataset and used feature engineering to enable a comparison of Anomaly Detection performance of classical models and a Deep-Learning model.


## Index
- [Summary](#summary)
- [Engenharia de Features üáßüá∑](#engenharia-de-features)
- [Feature Engineering üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø](#feature-engineering)

## Summary
The automatic anomaly detection in industrial robots is essential for operational security and equipment integrity. This work aproaches failure identification in a UR3e robotic arm, using an IMU dataset ([Casper 2](https://www.kaggle.com/datasets/hkayan/industrial-robotic-arm-imu-data-casper-1-and-2)), composed of more than 870 thousand samples collected in realistic scenarios created to emulate real life failures. Our work was divided in exploratory data analysis, pre-processing - with feature engineering and windowing -  and modelling, with hyperparam tuning. Among the evaluated model architectures are Gaussian Mixture, Isolation Forest and Convolutional Autoencoder.

> A detec√ß√£o autom√°tica de anomalias em rob√¥s industriais √© essencial para a seguran√ßa operacional e integridade dos equipamentos e m√°quinas utilizados. Este trabalho aborda a identifica√ß√£o de falhas em um bra√ßo rob√≥tico UR3e, usando um dataset IMU, baseado em unidades de medi√ß√£o inercial), o ([Casper 2](https://www.kaggle.com/datasets/hkayan/industrial-robotic-arm-imu-data-casper-1-and-2)), que √© composto por mais de 870 mil amostras coletadas em cen√°rios realistas criados para emular falhas da vida real. Nosso trabalho foi dividido em an√°lise explorat√≥ria de dados, pr√©-processamento - com engenharia de features e cria√ß√£o de janelas deslizantes - e modelagem, com tunagem de hiperpar√¢metros. Entre as arquiteturas de modelos avaliadas, est√£o a Mistura Gaussiana (Gaussian Mixture Model), Floresta de Isolamento e Autoencoder Convolucional.


## Engenharia de Features
Devido √† natureza distinta dos modelos avaliados, nossa estrat√©gia de engenharia de features precisou ser adaptada. Desta forma, a extra√ß√£o manual de features se restringiu aos modelos probabil√≠sticos e baseados em densidade, enquanto os dados crus da s√©rie temporal foram utilizados, sendo sujeitados apenas a enjanelamento deslizante e a normaliza√ß√£o

√â importante destacar a alta dimensionalidade do dataset usado, em que cada segundo consistia de 90 dimens√µes - 9 amostras, 10Hz. Ademais, esse n√∫mero se multiplicava pela quantidade de segundos em cada janela. Assim, como modelos cl√°ssicos frequentemente s√£o v√≠timas da Maldi√ß√£o da Dimensionalidade e s√£o comumente menos capazes de aprender rela√ß√µes complexas entre os dados, a engenharia e sele√ß√£o de features foi indispens√°vel.

Em ess√™ncia, esse processo no presente trabalho consistiu na cria√ß√£o de janelas e extra√ß√£o de features relativas a cada uma destas, atributos os quais enumeram-se abaixo, seguidos de uma explica√ß√£o simpl√≠stica de como eles podem ser √∫teis.

1. **M√©dia**: representa o valor m√©dio do sinal ao longo da janela, estando associada ao n√≠vel basal ou √† tend√™ncia local do movimento. Altera√ß√µes na m√©dia podem indicar mudan√ßas sistem√°ticas no comportamento do sistema.
2. **Desvio padr√£o**: quantifica a variabilidade do sinal dentro da janela, sendo associado √† intensidade das vibra√ß√µes.
3. **RMS (Root Mean Square)**: mede a energia do sinal, combinando informa√ß√µes de magnitude e variabilidade, sendo sens√≠vel tanto a oscila√ß√µes quanto a impactos.
4. **Pico-a-pico (*peak-to-peak*)**: corresponde √† diferen√ßa entre os valores m√°ximo e m√≠nimo do sinal na janela, capturando grandes varia√ß√µes de amplitude.
5. **Curtose**: caracteriza o grau de impulsividade do sinal, indicando a presen√ßa de picos abruptos e eventos raros de grande magnitude.
6. **Fator de crista (*crest factor*)**: definido como a raz√£o entre o valor de pico e o RMS, fornece uma medida normalizada da severidade dos picos em rela√ß√£o √† energia m√©dia do sinal.
7. **Frequ√™ncia dominante**: extra√≠da a partir da transformada de Fourier da janela, corresponde √† frequ√™ncia com maior energia espectral, permitindo capturar caracter√≠sticas din√¢micas do sistema, como resson√¢ncias ou mudan√ßas de regime de opera√ß√£o.

Isso levou a uma redu√ß√£o de * n atributos x tamanho da janela* dimens√µes (eg. 9 x 40) para (n atributos x 8) (eg. 72), no nosso tamanhho inicial de 40 amostras por janela (4s). No entanto, essas features ainda s√£o altamente correlacionadas e redundantes. Assim, ap√≥s an√°lise de correla√ß√£o linear, que manteve apenas 58 atributos, foi usado um PCA (ajustado apenas no conjunto de treino, com normaliza√ß√£o), preservando 95% da vari√¢ncia mas resultando em apenas 15 atributos.

Esse processo, em conjunto com outros passos do pr√©-processamento, foi estruturado em dois *pipelines*. O primeiro, para modelos cl√°ssicos, levou em conta a necessidade de ajustar o tamanho da janela como hiperpar√¢metro, o que requer recome√ßar a engenharia e sele√ß√£o de features. O segundo, para modelos de Deep-Learning, restringiu-se ao enjanelamento deslizante e normaliza√ß√£o. Testes preliminares durante a elabora√ß√£o do trabalho mostraram que esse passo foi essencial para o melhor funcionamento dos modelos classicos utilizados.

## Feature engineering
Due to the different nature of the evaluated models, our feature engineering strategy had to be adapted. Therefore, manual feature extraction was applied exclusively to probabilistic and density-based models, while for Deep-Learning based models, a Convolutional Autoencoder, in our case, raw time series data was used, only being subjected to windowing and normalization.

It's important to highlight the high dimensionality of the dataset used. Each second would ammount to 90 dimensions - 9 dimensions per sample, 10Hz. Besides that, each window consisted of more than a second. Since classical models often fall victim to the Curse of Dimensionality and are usually less able to understand deep correlations in data, feature engineering and selection was mandatory. In essence, our feature engineering consisted of the creation of sliding windows and later feature extraction and selection per window. For each sensor and each window, the following features were extracted, followed by a simplistic explanation of what they might portrait:

1. Mean - Average signal value
2. Standard Deviation - Signal variability
3. Root Mean Square - Total signal energy, sensitive to impacts
5. Peak to Peak - Captures large variations, corresponds to the difference between lowest and highest value
6. Kurtosis - Signal impulsiveness and peaks
7. Crest Factor - Ratio between peak value and RMS, normalizing the peak's severity
8. Dominant Frequency - Extracted from the Fourier Transform.

This lead to a reduction from *features x window size* dimensions (eg. 9 x 40) to *8 x features* (eg. 72), in our initial window size of 40 samples (4s). However, these engineered features are still highly redundant and correlated. After linear correlation analysis, which mantained only 58 features, a Principal Component Analysis was fitted - exclusively on the training set and after normalization - to preserve 95% of variance and thereby a reduction from 58 to 15 features was obtained.

This process, along with other pre-processing steps, was made into two pipelines. One was for classical models, since the hyperparam tuning step required window size tuning, which required also restarting the feature engineering and selection steps. The second was for Deep-Learning models, which only covered windowing and normalization. Preliminary testing during the work's elaboration showed this process was highly effective in increasing the baseline efficiency of our classical models.

### Extra - Visualization site
A simple website was elaborated to quickly compare visually the behavior of the robotic arm under normal *versus* abnormal conditions. In red is the "abnormal arm", in which constant oscilation-like movements can be seen. 
https://amcd.andrefgard.duckdns.org/3djs.html
