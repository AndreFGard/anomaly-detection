%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


\usepackage{graphicx}
\usepackage{xcolor}

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath

\renewcommand\refname{Referências}

\usepackage{algorithm}
\usepackage{algpseudocode}
% *** SPECIALIZED LIST PACKAGES ***
%
% \usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Detecção de Anomalias em Robôs Industriais}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{1\textsuperscript{st} Andre Saghaard}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{}\\
Recife, Brazil \\
afs15@cin.ufpe.br}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Bianca Paes}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
bpas@cin.ufpe.br}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Caio Nascimento}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
cns@cin.ufpe.br}
\and
\IEEEauthorblockN{4\textsuperscript{rd} Rodrigo Gomes}
\IEEEauthorblockA{\textit{Centro de Informática - UFPE} \\
%\textit{name of organization (of Aff.)}\\
Recife, Brazil \\
rgar@cin.ufpe.br}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
Breve apresentação do contexto do trabalho, problema/tema a ser abordado, soluções existentes, método proposto e resultados obtidos.
\end{abstract}

% no keywords

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introdução}

A motivação para este estudo decorre da crescente adoção de robôs industriais em operações críticas, onde a execução de tarefas repetitivas em proximidade com operadores exige monitoramento constante. Neste contexto, a identificação automática de anomalias é essencial para detectar falhas mecânicas e interferências externas, garantindo a integridade do equipamento e a segurança do processo.

A análise baseia-se em dados de sensores inerciais (IMU), capazes de capturar a dinâmica do manipulador. O acelerômetro monitora vibrações e impactos abruptos (indicativos de colisões), enquanto o giroscópio registra a velocidade angular, permitindo identificar oscilações ou atrasos causados por cargas excessivas. O magnetômetro, mede a orientação do sistema em relação ao campo magnético terrestre, apresentando variações mais lentas e sendo sensível a interferências magnéticas inesperadas. Como o robô opera em ciclos sequenciais, os sinais normais apresentam periodicidade bem definida; desvios nesse padrão, como alterações de forma de onda ou picos de energia, constituem as assinaturas principais de condições anômalas.

O conjunto de dados utilizado provém de experimentos públicos (IEEE PerCom 2023) realizados com um braço robótico UR3e em ambiente controlado. As amostras consistem em séries temporais coletadas a 10~Hz durante tarefas de \textit{pick-and-place}, abrangendo tanto o comportamento normal quanto cenários de falhas simuladas, como colisões (base e braço) e variações de carga. Essa diversidade torna o \textit{dataset} ideal para avaliar a eficácia de técnicas de análise exploratória, pré-processamento e aprendizado de máquina na caracterização de falhas industriais.

\section{Análise de Dados e Feature Engineering}

\subsection{Análise Exploratória dos Dados}

\subsubsection{Análise Exploratória Estrutural}

A análise exploratória estrutural foi conduzida com o objetivo de compreender a organização e os tipos de atributos presentes no conjunto de dados. Para garantir a integridade da avaliação durante as etapas de \textit{feature selection} e modelagem de forma a prevenir a tomada de decisão enviesada e o vazamento de dados, adotou-se uma estratégia de particionamento dos dados a priori. A divisão em subconjuntos de Treino, Validação e Teste foi realizada imediatamente após a coleta. O Conjunto de Validação, composto por 10\% dos dados Normais e 50\% dos dados de Falha (de cada cenário), foi utilizado para a Análise Exploratória de Dados (EDA) e demais etapas subsequentes.

O dataset é composto por séries temporais de sensores inerciais, contendo variáveis numéricas contínuas associadas às medições de acelerômetro, giroscópio e magnetômetro, nos eixos X, Y e Z; uma coluna temporal que representa o instante de coleta de cada amostra e uma variável indicativa da condição de operação do robô, utilizada como rótulo para diferenciar entre comportamento normal e anômalo. Particularmente, os dados anômalos são separados de acordo com o tipo de falha, sendo elas:

\begin{itemize}
  \item Hitting Platform, que lida com colisão contra a plataforma;
  \item Hitting Arm, colisão contra o próprio braço robótico;
  \item Extra Weight, esforço mecânico dado por peso extra;
  \item Earthquake, vibração estrutural externa.
\end{itemize}

Cada observação corresponde a uma leitura dos sensores em um determinado instante de tempo, sendo os dados organizados de forma sequencial. A variável temporal é representada por valores inteiros de alta resolução, indicando registros em escala de nanosegundos, reforçando o caráter temporal do problema. No entanto, com o objetivo de facilitar a interpretação e a análise de integridade temporal, os valores foram convertidos para milissegundos, mantendo a proporcionalidade entre as amostras e reduzindo a magnitude numérica dos registros. 

Durante a análise estrutural, foi identificada a presença de uma coluna textual associada à identificação do sensor, que por apresentar valor constante em todas as observações e não agregar informação discriminativa ao problema de detecção de anomalias, essa variável foi removida do conjunto de dados. Adicionalmente, foi realizada a verificação de duplicidade nos registros temporais, não sendo identificadas amostras com timestamps repetidos, o que indica consistência na indexação temporal das observações.

\subsubsection{Informações básicas}
O conjunto de dados normais analisado é composto por 874.937 amostras e 11 atributos após a etapa inicial de pré-processamento. Todas as variáveis de sensores são numéricas contínuas do tipo \textit{float64}, enquanto a variável alvo é representada por valores inteiros binários. O volume total de memória ocupado por esse dataset é de aproximadamente 73 MB.

Por outro lado, o conjunto de dados anômalos é composto por 49.185 amostras com os 11 atributos contínuos numéricos e a variável alvo binária. Com um volume total de memória de aproximadamente 10MB. Adicionalmente, o dataset possui um atributo \textit{scenario} que indica o tipo de falha a qual esse registro é associado, seguindo a proporção destacada na tabela abaixo.

\begin{table}[h]
\centering
\caption{Quantidade de anomalias por tipo de falha}
\label{tab:quantidade-anomalia-tipo-falha}
\begin{tabular}{llcc}
\hline
\multicolumn{1}{c}{\textbf{Cenário}} & \textbf{Quantidade} & \textbf{Proporção} \\ \hline
Hitting Platform & 14.967 & 0.3043 \\
Hitting Arm & 11.924 & 0.2424 \\
Earthquake & 11.409 & 0.2320 \\
Extra Weight & 10.885 & 0.2213
\end{tabular}
\end{table}

\subsubsection{Análise de Duplicatas, Valores Faltantes e \textit{Outliers}}
A integridade dos dados foi avaliada sob três perspectivas: redundância de registros, continuidade temporal e presença de valores extremos.

\paragraph{Duplicatas e Valores Nulos Explícitos}
Uma varredura inicial no conjunto de dados brutos não identificou linhas duplicadas ou valores nulos (\textit{NaN}) explícitos nas leituras dos sensores, tanto nos dados normais quanto anômalos. O sistema de aquisição registrou continuamente as 9 variáveis do IMU (acelerômetros, giroscópios e magnetômetros) sem falhas de escrita evidentes.

\paragraph{Análise de Continuidade Temporal}
Embora não houvesse \textit{NaNs} no arquivo original, a análise do intervalo entre amostras revelou um problema crítico de integridade temporal. A frequência nominal de coleta, era de 10 Hz (com \textit{Sampling Rate} de 100 ms). No entanto, observou-se um \textit{Jitter} (desvio padrão do intervalo de tempo) relevante de aproximadamente 22 ms, com 429 \textit{Gaps} Temporais significativos variando entre 2 ms e 342 ms, onde essa quantidade de perda de pacotes foi considerada quando o valor do \textit{Gap} foi maior que 2x a média, sendo categorizada como quebra de continuidade.

Para padronizar a frequência e facilitar o janelamento das séries temporais nas etapas seguintes, foi utilizada a técnica de \textit{Resampling}, impondo uma grade temporal rígida de 100 ms, conforme detalhado na seção de Pré-Processamento dos Dados. Nesse contexto, a irregularidade original foi exposta sob a forma de \textit{Gaps} temporais. No conjunto de dados Normal, o alinhamento gerou cerca de 44.766 lacunas onde não havia dados registrados no timestamp esperado.


\paragraph{Análise de \textit{Outliers}}
A análise de distribuição, por meior de Boxplots e Histogramas, detectou uma quantidade massiva de \textit{outliers} estatísticos, especialmente nos eixos do acelerômetro. Nos dados de colisão (\textit{Hitting Arm}), a curtose do eixo Z atingiu valores extremos ($>100$), com picos de aceleração de até 10g, muito superiores à faixa média normal de operação ($\pm 1g$). Entretenato, diferente de problemas de regressão clássicos, onde \textit{outliers} são ruídos a serem removidos, neste projeto eles constituem o próprio \textbf{sinal de interesse} (a falha mecânica).
\subsubsection{Análise Univariada} \label{subsec:analise-univariada}
Executar análises entre atributos e alvo de forma univariada com descrição estatística e visualizações de apoio.

\subsubsection{Análise Bivariada}

A análise bivariada partiu da hipótese de que a ocorrência de anomalias afeta o estado físico do robô, questionou-se se as falhas seriam capazes de "quebrar" o acoplamento mecânico entre sensores redundantes ou se as alterações seriam mais perceptíveis em pares de baixa correlação. Para investigar essa premissa, foram definidos cenários analíticos estratégicos, cujo objetivo foi garantir que diferentes tipos de relação entre sensores fossem explicitamente investigados. Essa escolha é importante porque pares de variáveis com comportamentos distintos (alta correlação, correlação média ou baixa correlação) tendem a responder de maneira diferente à introdução de falhas, fornecendo evidências complementares sobre a dinâmica do sistema. A métrica utilizada para quantificar a divergência entre as distribuições do alvo normal e anômalo foi a distância de Jensen-Shannon.

Foram definidos seis cenários bivariados. Nos dois cenários de redundância (pares com maior correlação física), a importância reside em avaliar sensores fortemente acoplados. Nesses casos, observou-se que, mesmo na presença de falhas, o padrão conjunto se mantém relativamente estável. Quantitativamente, isso se traduziu nas menores distâncias estatísticas observadas: o par (accx,accy) apresentou uma distância JS de apenas 0.12, seguido pelo par (accy,gyroy) com 0.14. Esses baixos valores indicam que falhas nem sempre rompem relações altamente correlacionadas, sugerindo que pares muito redundantes carregam informação similar e tendem a variar de forma conjunta, mesmo em condições anômalas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/redundancia.png}
\end{figure}

O cenário de linha de base, definido por um par com correlação próxima à média do sistema, foi incluído para representar um comportamento típico. O par (accx,magx) com uma distância JS de 0.20, ilustra essa referência. Esse valor intermediário permite avaliar como a resposta observada em cenários extremos de fato se diferencia do comportamento esperado em uma interação padrão entre sensores.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/media.png}
\end{figure}

Já no cenário de complementaridade, composto por sensores pouco correlacionados entre si, observou-se a mudança mais pronunciada entre os dados normais e de falha. A baixa correlação implica que cada sensor responde a aspectos diferentes do fenômeno físico. Quando ocorre uma falha, essas respostas divergentes ampliam drasticamente a separação entre as distribuições conjuntas. Isso ficou evidente nos pares: (accz,magz) atingiu a maior distância registrada (0.61). Esse alto valor confirma que a combinação de variáveis complementares é a mais sensível para capturar a divergência estatística introduzida pelas anomalias.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/diferentes.png}
\end{figure}

Por fim, os dois cenários de poder preditivo concentraram-se nos sensores mais correlacionados com o rótulo de falha. A importância desses cenários está em avaliar se sensores individualmente informativos também apresentam mudanças relevantes quando analisados em conjunto. Os resultados indicaram que a introdução de falhas altera a densidade conjunta, embora de forma menos extrema que na complementaridade, ou seja, o que importa não é unicamente a importância do sensor, mas também sua correlação para definir se o par vai se comportar de maneira mais parecida ou não.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/top2.png}
\end{figure}

Em suma, a análise validou a hipótese inicial: pares altamente correlacionados tendem a mascarar a anomalia, enquanto pares com baixa correlação evidenciam as alterações de forma mais clara.

\subsubsection{Análise Multivariada}

Na análise multivariada, todas as variáveis dos sensores foram consideradas simultaneamente por meio do PCA (Principal Component Analysis), após padronização. A projeção nos dois primeiros componentes revelou que as anomalias não são facilmente separáveis dos dados normais. As amostras de falha aparecem cercadas por pontos normais e distribuídas em diferentes regiões do espaço reduzido, indicando que não existe um único padrão geométrico simples que caracterize todas as falhas.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/top2.png}
\end{figure}

Apesar dessa sobreposição, a visualização evidenciou diferenças estruturais relevantes. Em diversas regiões do espaço PCA, observam-se concentrações de falhas com orientações e dispersões distintas, refletindo o impacto específico de cada tipo de anomalia sobre o sistema. Isso indica que, embora não haja separação linear clara, as falhas alteram a dinâmica multivariada de maneira consistente, produzindo padrões locais diferenciados.

As setas do biplot permitiram interpretar a contribuição de cada sensor para essas diferenças, destacando quais variáveis influenciam mais fortemente determinadas direções do espaço PCA. Sensores com vetores mais extensos tiveram maior peso na organização dos dados, ajudando a explicar por que determinadas anomalias se manifestam em regiões específicas do plano.

A análise foi complementada pela visualização temporal de janelas de 30 segundos no espaço PCA, utilizando uma régua visual fixa para todos os cenários. Essa abordagem evidenciou que o comportamento normal tende a produzir trajetórias mais compactas e regulares, enquanto os cenários de falha apresentam trajetórias mais dispersas e irregulares, reforçando o impacto dinâmico das anomalias ao longo do tempo.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/temporal.png}
\end{figure}

No que se refere às variáveis derivadas, foram calculadas magnitudes físicas da aceleração, do giroscópio e do magnetômetro, com o objetivo de condensar informações multieixo em medidas escalares fisicamente interpretáveis. 

Testes exploratórios básicos, como a comparação de distribuições entre classes e análises de separação estatística, indicaram que essas variáveis capturam alterações relevantes introduzidas pelas falhas, mostrando potencial para uso na otimização dos modelos subsequentes, permitindo, por exemplo, estratégias de redução de dimensionalidade que mantenham a interpretabilidade física do fenômeno ao diminuir o número de variáveis de entrada.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/importancia.png}
\end{figure}

Por fim, aplicou-se o K-Means para identificar grupos de interesse no espaço formado pelas variáveis originais. O uso de um método não supervisionado é adequado nesse contexto, pois permite investigar a estrutura intrínseca dos dados sem recorrer aos rótulos. Os resultados mostraram que, considerando apenas os dados brutos, não foi possível identificar um grupo claramente dominante em termos de concentração de falhas.

\begin{table}[H]
    \centering
    \begin{tabular}{c c c}
        \hline
        \textbf{Cluster} & \textbf{Normal (\%)} & \textbf{Falha (\%)} \\
        \hline
        0 & 96.601872 & 3.398128 \\
        1 & 96.528435 & 3.471565 \\
        2 & 96.646539 & 3.353461 \\
        \hline
    \end{tabular}
\end{table}


\subsection{Pré-processamento dos dados}
Apresentar ações referentes ao pré-processamento de dados a exemplo de:

\subsubsection{Tratamento de Valores Faltantes}

Para corrigir os problemas de  \textit{timestamps} irregularmente espaçadas e amostras faltantes, sem descartar dados, optou-se pela \textbf{interpolação linear} dos valores faltantes gerados pelo \textit{Resampling}. Essa abordagem preservou a tendência do movimento entre os pontos conhecidos, restaurando a continuidade necessária para a extração de \textit{features} de janela deslizante.

Para os conjuntos de dados anômalos, a etapa de regularização temporal com \textit{Resampling} e Interpolação foi aplicada de forma iterativa e independente para cada cenário de falha, ao invés da aplicação direta sobre o conjunto anômalo completo. Essa abordagem foi necessária para prevenir as descontinuidades temporais, visto que os experimentos de falha foram registrados em contextos diferentes e com \textit{Gaps} de minutos a horas entre si e a imposição de uma grade temporal contínua de 10Hz no dataset completo forçaria a criação de milhares de linhas vazias para preencher esses intervalos e a interpolação linear geraria dados sintéticos falsos, o que tornaria inviável alimentar o modelo com esses dados, mesmo com etapas subsequentes de pré-processamento.


\subsubsection{Tratamento de Outliers e Feature Scaling}
Conforme detalhado anteriormente, os \textit{outliers} identificados representam uma parte importante do problema e representam medições verossímeis. Consequentemente, optou-se por \textbf{não removê-los}. No entanto, tendo em mente a fonte dos dados e a natureza dos sensores, foi necessário aplicar um filtro para reduzir o ruído dos sinais, sendo utilizado o Savitzky-Golay, que ajusta polinômios localmente, por sua capacidade de preservar melhor a forma e pico dos sinais que outros baseados em médias rolantes.
Adiconalmente, para mitigar o impacto desses valores extremos do sensores na normalização dos dados, substituiu-se o \textit{StandardScaler} (sensível à média/desvio padrão) pelo \textbf{\textit{RobustScaler}}, sendo este ajustado somente ao conjunto de treinamento dos dados normais e posteriormente usado para transformar os outros conjuntos. Este escalonador utiliza a mediana e o intervalo interquartil (IQR), garantindo que os picos de colisão permaneçam destacados na escala transformada, preservando a assinatura da anomalia para o modelo. 


\subsubsection{Detecção e Tratamento de Duplicadas}
Não havia duplicadas no \textit{dataset}, devido ao processo de geração deste ~\cite{casper}. 


\subsubsection{Encoding de Variáveis Categóricas}
Os dados não contém qualquer variável categórica, sendo desnecessárias estratégias de \textit{encoding}.

\subsection{Divisão dos Dados}
Os dados normais, não-anomalos, conforme ilustrado em \ref{tab:dataSplit}, foram dividos em 60\%, 20\% e 20\% entre os conjuntos de treinamento, validação e teste, respectivamente, enquanto foi dividido em 50\% para a validação e 50\% para o conjunto de testes. Em ambos os casos, a divisão respeitou a ordenação dos dados ao longo do tempo, visando evitar o vazamento de informações e a violação das relações temporais entre os pontos de dados.

Além disso, no caso dos dados anômalos, foi feita divisão estratificada, para garantir que cada classe de anomalia, que ocorreram cada uma independentemente e não concomitantemente, como os choques na plataforma e os choques no braço robótico, estivessem proporcionalmente representadas nos conjuntos de validação e teste.

\begin{table}[htbp]
    \centering
    \caption{Divisão Percentual dos Conjuntos de Dados)}
    \label{tab:dataSplit}
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Conjunto de Dados} & \textbf{Treino (\%)} & \textbf{Validação (\%)} & \textbf{Teste (\%)} \\
        \hline
        Normal & 60,0 & 20,0 & 20,0 \\
        \hline
        Anomalia & 0,0 & 50,0 & 50,0 \\
        \hline
    \end{tabular}
    \vspace{-1mm} % Ajuste de espaçamento, se necessário
\end{table}

\subsection{Feature Engineering}
A estratégia de engenharia de atributos (\textit{Feature Engineering}) adotada neste trabalho foi adaptada aos diferentes de tipos de modelos avalaidos. Processo de extração manual de atributos  foi aplicado \textbf{exclusivamente} aos modelos probabilísticos e baseados em densidade (Isolation Forest, Gaussian Mixture Models).

Para as abordagens baseadas em Deep Learning, foram usados os dados brutos das séries temporais, submetidos apenas à criação de janelas, considerando a capacidade dessas arquiteturas de fazer (\textit{representation learning}) e capturar dependências temporais complexas. Em contrapartida, os modelos clássicos carecem da habilidade nativa de interpretar a sequencialidade temporal de alta dimensão dos sensores brutos (90 dimensões por segundo de janela) tornando imperativa a transformação desses dados em vetores de estatísticas descritivas que sintetizem o comportamento dinâmico e espectral do robô.

Dessa forma, o \textit{pipeline} de engenharia de atributos para os modelos clássicos foi feito em três etapas: Criação de janelas, extração e seleção, conforme detalhado a seguir.

\subsubsection{Criação de janelas}
Para a criação de janelas, foram utilizadas janelas móveis (\textit{sliding windows})\ref{windows}, que possuem uma intercessão ajustável com as janelas imediatamente vizinhas Um algoritmo ilustrativo para a criação de janelas deslizantes esa descrito em \ref{alg:sliding_window}.

Cada parte dos dados passou por esse processo isoladamente, e janelas incompletas foram descartadas para garantir a uniformidade das matrizes resultantes. Por exemplo, visto que a frequência de coleta de dados foi de 10Hz, uma janela de 40 amostras captura 4 segundos de funcionamento do braço robótico. Ademais, os parâmetros das janelas foram considerados como hiperparâmetros na etapa da modelagem, para que sejam escolhidos otimamente. Esta escolha é muito importante, porque o tamanho da janela depende muito dos modelos, e os eventos de interesse são muitos particulares do problema. No caso desse dataset, observamos que os eventos de interesse de fato exigiam uma análise um período de alguns segundos.
\begin{algorithm}
\caption{Segmentação em Janelas Deslizantes (Sliding Windows)}\label{alg:sliding_window}
\begin{algorithmic}
\Require $D$ (Dados $N \times F$), $L$ (Tamanho da Janela), $O$ (Overlap)
\Ensure $\mathcal{W}$ (Tensor de janelas $M \times L \times F$)

\State $S \gets L - O$
\State $N \gets \text{rows}(D)$
\State $\mathcal{W} \gets \emptyset$ 
\State $i \gets 0$

\While{$i + L \leq N$}
    \State $w \gets D[i : i + L, :]$ 
    \State $\mathcal{W} \gets \mathcal{W} \cup \{w\}$ 
    \State $i \gets i + S$ 
\EndWhile

\State \Return $\mathcal{W}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Extração e seleção de features}
Nesta etapa, buscamos transformar os sinais dos sensores em uma representação mais informativa, bem como adaptá-la às limitações dos modelos que não usam Deep Learning  usados neste trabalho, que não lidam bem com a grande quantidade de dimensões envolvida e com a alta correlação entre features. Esse processo se dividiu entre a extração e a seleção de features.

Inicialmente, fizemos a extração de features a nível de amostra. A partir dos sinais originais, criamos variáveis derivadas utilizando a interpretação física do problema e do que cada varíavel representava, como a norma vetorial de cada sensor, que captura a magnitude total da mudança por ele registrada, unindo os eixos.

Em seguida, os sinais e seus atributos derivados foram segmentados em janelas como descrito a cima. Para cada janela, foram extraídas estatísticas agregadas calculadas exclusivamente com as \textit{features} originais, agregando tendências e informações sobre o periodo inteiro de tempo representado pelo tamanho da janela.
\begin{enumerate}
    \item \textbf{Média:} representa o valor médio do sinal ao longo da janela e está associada ao nível basal ou tendência local do movimento. Alterações na média podem indicar mudanças sistemáticas no comportamento do sistema, como inclinações persistentes ou deslocamentos contínuos.
    
    \item \textbf{Desvio padrão:} quantifica a variabilidade do sinal dentro da janela, sendo fortemente associado à intensidade de vibrações.
    
    \item \textbf{RMS (Root Mean Square):} mede a energia total do sinal, combinando informações de magnitude e variabilidade. Diferentemente da média, o RMS é sensível tanto a oscilações quanto a impactos.
    
    \item \textbf{Pico-a-pico (peak-to-peak):} corresponde à diferença entre os valores máximo e mínimo do sinal na janela, tambem capturando grandes variações.
    
    \item \textbf{Curtose:} caracteriza o grau de impulsividade do sinal, indicando a presença de picos abruptos e eventos raros de grande magnitude..
    
    \item \textbf{Fator de crista (crest factor):} definido como a razão entre o valor de pico e o RMS, fornece uma medida normalizada da severidade dos picos em relação à energia média do sinal. Essa \textit{feature} é especialmente útil para diferenciar vibrações contínuas de impactos pontuais.
    
    \item \textbf{Frequência dominante:} extraída a partir da transformada de Fourier da janela, indica a frequência com maior energia espectral. Essa informação permite capturar características dinâmicas do sistema, como ressonâncias, mudanças de regime de operação ou vibrações induzidas por cargas externas.
\end{enumerate}

Essas \textit{features} sintetizam muitas propriedades fundamentais do comportamento do sinal dentro da janela e constituem uma representação comparativamente compacta desse comportamento. Dessa forma, ao invés de termos um total de \(features*tamanhoDaJanela\) dimensões, ou seja, 360, no caso dos nossos 9 sensores e uma janela de 40 amostras, obtemos apenas 72 dimensões.

o entanto, apesar de representar uma redução considerável da dimensionalidade, essas \textit{features} ainda podem apresentar elevada redundância estatística. Em particular, muitas das estatísticas extraídas descrevem aspectos relacionados do sinal (por exemplo, desvio padrão, RMS e pico-a-pico), o que resulta em fortes correlações lineares entre atributos. A presença desse tipo de redundância pode prejudicar o desempenho de modelos probabilísticos e baseados em densidade, além de aumentar o custo computacional e dificultar a interpretação dos resultados.

Dessa forma, foi aplicada uma etapa explícita de seleção de \textit{features}. Inicialmente, realizou-se uma análise de correlação linear entre os atributos extraídos, utilizando o coeficiente de correlação de Pearson. Para cada par de \textit{features} cuja correlação absoluta excedia um limiar de 0,95, apenas uma delas foi mantida. Essa estratégia visa eliminar atributos altamente redundantes, preservando, ao mesmo tempo, a maior diversidade possível de informações relevantes. Após essa etapa, o número de \textit{features} foi reduzido de 72 para 58.

Mesmo após a remoção de correlações elevadas, o espaço de atributos ainda permanecia relativamente grande e com possíveis dependências lineares de ordem superior. Assim, aplicou-se uma etapa adicional de redução de dimensionalidade por meio da Análise de Componentes Principais (PCA). O PCA foi ajustado exclusivamente sobre o conjunto de treinamento, após normalização robusta dos dados, e o número de componentes foi selecionado de forma a preservar pelo menos 95\% da variância total dos dados. Como resultado, o espaço de atributos foi reduzido de 58 para 15 componentes principais, mantendo uma variância explicada acumulada de aproximadamente 95,28%.

Essa combinação de seleção por correlação e redução via PCA permitiu obter uma representação compacta, pouco redundante e estatisticamente bem condicionada dos dados, adequada às premissas dos modelos clássicos avaliados neste trabalho. Além disso, ao concentrar a maior parte da variabilidade dos sinais em um número reduzido de componentes, essa abordagem contribui para maior estabilidade numérica, melhor generalização e menor sensibilidade a ruído.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{imagens/variancia.png}
\end{figure}



\section{Modelagem}
Nesta seção deverá ser feita uma breve revisão dos algoritmos selecionados. Além disso, justificar a escolha do algoritmo juntamente com hiperparâmetros a serem testados. Importante explicitar qual(is) foi(ram) o(s) espaço(s) de busca utilizado, bem como a técnica escolhida para tunagem de hiperparâmetros.

\subsection{Modelo A}
\subsubsection{Conceitos Básicos}
\subsubsection{Justificativa}
\subsubsection{Espaço de Busca}
\subsubsection{Hiperparâmetros Selecionados}
\subsection{Modelo B}
\subsubsection{Conceitos Básicos}
\subsubsection{Justificativa}
\subsubsection{Espaço de Busca}
\subsubsection{Hiperparâmetros Selecionados}
\subsection{Modelo C}
\subsubsection{Conceitos Básicos}
\subsubsection{Justificativa}
\subsubsection{Espaço de Busca}
\subsubsection{Hiperparâmetros Selecionados}

\section{Análise e Comparação de Resultados}
Deverá conter as métricas que foram utilizadas para a análise juntamente com revisão de conceito e justificativas. É fundamental comparar os resultados obtidos entre os diferentes modelos treinados. Além disso, é interessante utilizar ferramentas estatísticas e/ou testes de hipótese quando cabível.

\section{Conclusão e Discussão}
Explicar os principais achados ao longo do trabalho bem como vantagens e limitações de métodos e/ou algoritmos selecionados. Além disso, apresentar principais \textit{insights} extraídos e potenciais trabalhos futuros.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].

% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\begin{thebibliography}{9}

\bibitem{casper_acm}
H.~Kayan, R.~Heartfield, O.~Rana, P.~Burnap, and C.~Perera,
``CASPER: Context-Aware IoT Anomaly Detection System for Industrial Robotic Arms,''
\emph{ACM Transactions on Internet of Things},
vol.~5, no.~3, art.~18, Aug.~2024, doi: 10.1145/3670414.

\bibitem{percom_realtime}
H.~Kayan, R.~Heartfield, O.~Rana, P.~Burnap, and C.~Perera,
``Real-Time Anomaly Detection for Industrial Robotic Arms Using Edge Computing,''
\emph{2023 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)},
2023.

\bibitem{review_timeseries}
A.~Blázquez-García, M.~S.~Del Aguila, I.~López, P.~López, and F.~Sánchez,
``A review on outlier/anomaly detection in time series data,''
\emph{ACM Computing Surveys},
vol.~54, no.~3, pp.~1--33, 2021.

\bibitem{mahalanobis_svdd}
Y.~Yang et al.,
``Unsupervised Anomaly Detection for Autonomous Robots via Mahalanobis SVDD with Audio-IMU Fusion,''
\emph{arXiv preprint arXiv:2505.05811},
2025.

\bibitem{chirayil_anomaly}
S.~Chirayil Nandakumar et al.,
``Anomaly detection methods in autonomous robotic missions,''
\emph{Sensors},
vol.~24, no.~4, p.~1330, 2024.
\bibitem{windows}
Keogh, E., Lin, J. Clustering of time-series subsequences is meaningless: implications for previous and future research. \emp{Knowl Inf Syst 8}, 154–177 (2005).

\end{thebibliography}




% that's all folks
\end{document}